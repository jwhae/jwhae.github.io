<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI | Optimizers</title>
  <meta name="description" content="Learn about optimizers used in AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="How to configure Chalk">
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://jwhae.github.io/posts/overview-optimizers ">
  <meta property="og:description" content="Overview of Deep Learning Optimizers">
  <meta property="og:site_name" content="Chalk">
  
  <meta property="og:image" content="http://jwhae.github.io/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
  <meta name="twitter:image" content="http://jwhae.github.io/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">

  <link href="http://jwhae.github.io/feed.xml" type="application/rss+xml" rel="alternate" title="Chalk Last 10 blog posts" />
  <link rel="icon" type="image/x-icon" href="/assets/favicon-dark-11327753546b2135c989eee5cd83497a2734b702928d016839d795f6c706e3d5.ico">
  <link rel="apple-touch-icon" href="/assets/apple-touch-icon-dark-d161409442b7e523089f24d08d0a55951549ece7504207c376d53b020713494d.png">
  <link rel="stylesheet" type="text/css" href="/assets/dark-831218bc9e41aef39ee6a0bae4501195bccafcc13101ae2b9cd20493a6ec04c0.css">
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav scrollappear">
          <a href="/" class="header-logo" title="AI : Optmization">Optimizers</a>
            <ul class="header-links">
              <li>
                <a href="/about" title="About me">
                  <svg xmlns="http://www.w3.org/2000/svg" class="icon-about">
                    <use href="/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about" xlink:href="/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about"></use>
                  </svg>
                </a>
              </li>
              <li>
                <a href="https://github.com/jwhae" rel="noreferrer noopener" target="_blank" title="GitHub">
                  <svg xmlns="http://www.w3.org/2000/svg" class="icon-github">
                    <use href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github" xlink:href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github"></use>
                  </svg>
                </a>
              </li>
              <li>
                <a href="/feed.xml" rel="noreferrer noopener" target="_blank" title="RSS">
                  <svg xmlns="http://www.w3.org/2000/svg" class="icon-rss">
                    <use href="/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss" xlink:href="/assets/rss-541ec5cea9cefd10d2fcfec01888f3f231a8829940249835fa7b7b3a12ae0d0d.svg#icon-rss"></use>
                  </svg>
                </a>
              </li>
          </ul>
        </nav>
        
        <!-- Content of the blog post starts here -->
        <article class="article scrollappear">
          <header class="article-header">
            <h1>Overview of AI Optimizers</h1>
            <p>The main purpose of training a AI model is to identify parameters that minimizes the result of a <code class="highlighter-rouge">loss function</code>. 
               This can also be defined as a <em><code class="highlighter-rouge">optimization</code></em> of parameters in AI model. 
            </p>
            <div class="article-list-footer">
              <span class="article-list-date"> November 08, 2020 </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                <a href="/tag/web" title="See all posts with tag 'AI'">AI</a>
                <a href="/tag/jekyll" title="See all posts with tag 'Android'">Android</a>
              </div>
            </div>
          </header>

          <div class="article-content">
            <p>There are many reasons to why different means of optimization is applied to during the training phase of AI model. For instance, let's look at SGD</p>
            <figure class="highlight">
              <!-- 
                code block 
                watch out for identation, the code block require each of the line to start from the left corner  
              -->
              <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- SGD --&gt;</span>
<span class="na">class</span> SGD :
    <span class="nt">def</span> __init__(self, lr= 0.01) : 
        <span class="na">self</span>.lr = lr
                
    <span class="nt">def</span> update(self, params, grads):
        <span class="s">for</span> key <span class="s">in</span> params.keys():
            params[key] -= <span class="na">self</span>.lr * grads[key]
    </code></pre></figure>
            <p>SGD is one of the simplest optimization method available. It achieves <code class="highlighter-rouge">optimization</code> by taking the differentiation of the gradient until it reaches the global optimal value</p>
            <p>However, it may be very inefficient depending on the situation. For instance</p>
            <p>f(x, y) = 1/20 * x² + y²</p>
            
            
            <p>Momentum</p>
            <figure class="highlight">
              <!-- 
                code block 
                watch out for identation, the code block require each of the line to start from the left corner  
              -->
              <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- Momentum --&gt;</span>
<span class="na">class</span> Momentum :
    <span class="nt">def</span> __init__(self, lr= 0.01, momentum = 0.9) : 
        <span class="na">self</span>.lr = lr
        <span class="na">self</span>.momentum = momentum
        <span class="na">self</span>.v = None
                
    <span class="nt">def</span> update(self, params, grads):
        if <span class="na">self</span>.v is None:
            <span class="na">self</span>.v = {}
            
            <span class="s">for</span> key, val <span class="s">in</span> params.items():
                <span class="na">self</span>.v[key] = np.zeros_like(val)
               
        <span class="s">for</span> key <span class="s">in</span> params.keys():
            <span class="na">self</span>.v[key] = <span class="na">self</span>.momentum * <span class="na">self</span>.v[key] - <span class="c">self</span>.lr * grads[key]
            params[key] += <span class="na">self</span>.v[key]
    </code></pre></figure>

            <p>SGD is one of the simplest optimization method available. It achieves <code class="highlighter-rouge">optimization</code> by taking the differentiation of the gradient until it reaches the global optimal value</p>
            <p>However, it may be very inefficient depending on the situation. For instance</p>
            <p>f(x, y) = 1/20 * x² + y²</p>
            
            <p>Explain AdaGrad</p>
            <figure class="highlight">
            <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- AdaGrad --&gt;</span>
<span class="na">class</span> AdaGrad :
    <span class="nt">def</span> __init__(self, lr= 0.01) : 
        <span class="na">self</span>.lr = lr
        <span class="na">self</span>.h = None
                
    <span class="nt">def</span> update(self, params, grads):
        if <span class="na">self</span>.h is None:
            <span class="na">self</span>.h = {}
            
            <span class="s">for</span> key, val in params.items():
                <span class="c">self</span>.h[key] = np.zeros_like(val)
               
        <span class="s">for</span> key in params.keys():
            <span class="na">self</span>.h[key] = grads[key] * grads[key]
            params[key] -= <span class="na">self</span>.lr * grads[key] / (np.sqrt(<span class="na">self</span>.h[key] + 1e-7)
    </code></pre></figure>
    
            <p>Explain Nesterov (Root Mean Square Propagation)</p>
            <figure class="highlight">
            <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- Nestrov --&gt;</span>
<span class="na">class</span> Adam :
    <span class="nt">def</span> __init__(self, momentum = 0.9) : 
        <span class="na">self</span>.lr = lr
        <span class="na">self</span>.momentum = momentum
        <span class="na">self</span>.v = None
                
    <span class="nt">def</span> update(self, params, grads):
        if <span class="na">self</span>.v is None:
            <span class="na">self</span>.v = {}
            
            <span class="s">for</span> key, val in params.items():
                <span class="na">self</span>.v[key] = np.zeros_like(val)
                
        <span class="s">for</span> key in params.keys():
            <span class="na">self</span>.v[key] *= self.momentum
            <span class="na">self</span>.v[key] -= <span class="c">self</span>.lr * grads[key]
            params[key] += <span class="na">self</span>.momentum ** 2 * <span class="na">self</span>.v[key]
            params[key] -= (1 + <span class="na">self</span>.momentum) * <span class="na">self</span>.lr * grads[param]
            
            
    </code></pre></figure>
  
  
            <p>Explain RMSprop (Root Mean Square Propagation)</p>
            <figure class="highlight">
            <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- RMSDrop --&gt;</span>
<span class="na">class</span> Adam :
    <span class="nt">def</span> __init__(self, lr= 0.01, decay_rate = 0.99) : 
        <span class="c">self</span>.lr = lr
        <span class="c">self</span>.decay_rate = decay_rate
        <span class="c">self</span>.h = None
                
    <span class="nt">def</span> update(self, params, grads):
        if <span class="na">self</span>.h is None:
            <span class="na">self</span>.h = {}
            
            <span class="s">for</span> key, val <span class="s">in</span> params.items():
                <span class="na">self</span>.h[key] = np.zeros_like(val)
                
        <span class="s">for</span> key <span class="s">in</span> params.keys():
            <span class="na">self</span>.h[key] *= <span class="na">self</span>.decay_rate
            <span class="na">self</span>.h[key] += (1 - <span class="na">self</span>.decay_rate) * grads[key]**2
            
            params[key] -= <span class="na">self</span>.lr * grads[key] / (np.sqrt(<span class="na">self</span>.h[key] + 1e-7)
            
    </code></pre></figure>
  
<p>Explain Adam</p>
            <figure class="highlight">
            <pre><code class="language-html" data-lang="html"><span class="c">&lt;-- Adam --&gt;</span>
<span class="na">class</span> Adam :
    <span class="nt">def</span> __init__(self, lr= 0.01, beta1 = 0.9 beta2 = 0.999) : 
        <span class="na">self</span>.lr = lr
        <span class="na">self</span>.beta1 = beta1
        <span class="na">self</span>.beta2 = beta2
        <span class="na">self</span>.iter = 0
        <span class="na">self</span>.m = None
        <span class="na">self</span>.v = None
                
    <span class="nt">def</span> update(self, params, grads):
        if <span class="na">self</span>.m is None:
            <span class="na">self</span>.m = {}
            
            <span class="s">for</span> key, val <span class="s">in</span> params.items():
                <span class="na">self</span>.m[key] = np.zeros_like(val)
                <span class="na">self</span>.v[key] = np.zeros_like(val)
                
        <span class="c">self</span>.iter += 1 
        lr_t = <span class="na">self</span>.lr * np.sqrt(1.0 - <span class="na">self</span>.beta2 ** <span class="na">self</span>.iter) / (1.0 - <span class="na">self</span>.beta1 ** <span class="c">self</span>.iter)
               
        <span class="s">for</span> key <span class="s">in</span> params.keys():
            <span class="na">self</span>.m[key] += (1 - self.beta1) * (grads[key] - <span class="na">self</span>.m[key])
            <span class="na">self</span>.v[key] += (1 - self.beta2) * (grads[key]**2 - <span class="na">self</span>.v[key])
            
            params[key] -= lr_t * <span class="na">self</span>.m[key] / (np.sqrt(<span class="na">self</span>.v[key] + 1e-7)
            
    </code></pre></figure>


            
        <footer class="footer scrollappear">
          <p>
            Chalk is a high quality, completely customizable, performant and 100% free
            blog template for Jekyll built by
            <a href="/about" title="About me">Nielsen Ramon</a>. Download it <a href="https://github.com/nielsenramon/chalk" rel="noreferrer noopener" target="_blank" title="Download Chalk">here</a>.
          </p>
        </footer>
      </div>
    </div>
  </main>
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-28631876-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-28631876-6');
  </script>

<script src="/assets/vendor-130c9c254effc51f3283620bc635851da7b99c20901216948f11ba72ee13317f.js" type="text/javascript"></script>
<script src="/assets/webfonts-96493456d319d1bf419afdf8701552d4d486fee6afd304897d4fd81eb4e0cc0b.js" type="text/javascript"></script>
<script src="/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js" type="text/javascript"></script>
<script src="/assets/application-cfde13ac81ddaf4351b2e739603e2baf688d0fcc9aba613fe62bbb1c7b037fb9.js" type="text/javascript"></script>


</body>
</html>
